# ğŸ›ï¸ KIáº¾N TRÃšC Há»† THá»NG DATA LAKEHOUSE

## ğŸ“‹ Tá»•ng Quan

Há»‡ thá»‘ng Data Lakehouse Ä‘Æ°á»£c xÃ¢y dá»±ng theo **Kiáº¿n trÃºc Medallion** vá»›i 3 táº§ng dá»¯ liá»‡u:
- **Bronze Layer**: Dá»¯ liá»‡u thÃ´ (Raw Data)
- **Silver Layer**: Dá»¯ liá»‡u Ä‘Ã£ lÃ m sáº¡ch (Cleaned Data)
- **Gold Layer**: Dá»¯ liá»‡u nghiá»‡p vá»¥ (Business-Ready Data)

## ğŸ¯ Use Case: E-commerce Event History

**Dataset**: eCommerce Events History in Cosmetics Shop (Kaggle)
- ~20 triá»‡u events
- Dá»¯ liá»‡u hÃ nh vi ngÆ°á»i dÃ¹ng: view, cart, purchase
- Thá»i gian: Oct 2019 - Apr 2020

## ğŸ”§ Stack CÃ´ng Nghá»‡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        VISUALIZATION LAYER                          â”‚
â”‚                         Apache Superset                             â”‚
â”‚                    (Dashboard & BI Reports)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         SERVING LAYER                                â”‚
â”‚                          ClickHouse                                  â”‚
â”‚               (OLAP Database - Sub-second Queries)                   â”‚
â”‚                     [IcebergS3 Engine]                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      TRANSFORMATION LAYER                            â”‚
â”‚              dbt (data build tool) + Apache Spark                    â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚    BRONZE    â”‚â”€â”€â”€â–¶â”‚    SILVER    â”‚â”€â”€â”€â–¶â”‚     GOLD     â”‚           â”‚
â”‚  â”‚  (Raw Data)  â”‚    â”‚(Cleaned Data)â”‚    â”‚(Aggregated)  â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        TABLE FORMAT                                  â”‚
â”‚                       Apache Iceberg                                 â”‚
â”‚    [Schema Evolution, Time Travel, Partitioning, Z-Ordering]        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        STORAGE LAYER                                 â”‚
â”‚                           MinIO                                      â”‚
â”‚                (S3-Compatible Object Storage)                        â”‚
â”‚                                                                      â”‚
â”‚     s3://lakehouse/bronze/    s3://lakehouse/silver/                â”‚
â”‚     s3://lakehouse/gold/      s3://lakehouse/warehouse/             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       CATALOG SERVICE                                â”‚
â”‚                    Iceberg REST Catalog                              â”‚
â”‚              (Nessie / Polaris / Custom REST)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Cáº¥u TrÃºc ThÆ° Má»¥c

```
lakehouse-project/
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ docker-compose.yml          # Main orchestration
â”‚   â”œâ”€â”€ spark/
â”‚   â”‚   â””â”€â”€ Dockerfile              # Custom Spark image
â”‚   â”œâ”€â”€ superset/
â”‚   â”‚   â””â”€â”€ superset_config.py      # Superset configuration
â”‚   â””â”€â”€ clickhouse/
â”‚       â””â”€â”€ config.xml              # ClickHouse configuration
â”œâ”€â”€ spark/
â”‚   â”œâ”€â”€ jobs/
â”‚   â”‚   â”œâ”€â”€ bronze/
â”‚   â”‚   â”‚   â””â”€â”€ ingest_events.py    # Raw data ingestion
â”‚   â”‚   â”œâ”€â”€ silver/
â”‚   â”‚   â”‚   â””â”€â”€ clean_events.py     # Data cleaning
â”‚   â”‚   â””â”€â”€ gold/
â”‚   â”‚       â””â”€â”€ aggregate_sales.py  # Business aggregations
â”‚   â””â”€â”€ conf/
â”‚       â””â”€â”€ spark-defaults.conf
â”œâ”€â”€ dbt/
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ profiles.yml
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/                # Bronze â†’ Silver
â”‚   â”‚   â”œâ”€â”€ marts/                  # Silver â†’ Gold
â”‚   â”‚   â””â”€â”€ schema.yml
â”‚   â””â”€â”€ tests/
â”œâ”€â”€ clickhouse/
â”‚   â”œâ”€â”€ migrations/
â”‚   â”‚   â””â”€â”€ 001_create_tables.sql
â”‚   â””â”€â”€ queries/
â”œâ”€â”€ superset/
â”‚   â””â”€â”€ dashboards/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                        # Source CSV files
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploration.ipynb
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.sh                    # Initial setup
â”‚   â”œâ”€â”€ ingest.sh                   # Run ingestion
â”‚   â””â”€â”€ transform.sh                # Run transformations
â”œâ”€â”€ README.md
â””â”€â”€ Makefile                        # Automation commands
```

## ğŸ”„ Data Flow Chi Tiáº¿t

### Step 1: Ingestion (Bronze Layer)
```
CSV Files â†’ Spark â†’ Iceberg Tables (Bronze) â†’ MinIO
                         â”‚
                         â””â”€â”€ Metadata: _ingestion_time, _source_file
```

### Step 2: Transformation (Silver Layer)
```
Bronze Tables â†’ dbt/Spark â†’ Silver Tables
                    â”‚
                    â””â”€â”€ Cleaning: Deduplication, Type casting, Null handling
```

### Step 3: Aggregation (Gold Layer)
```
Silver Tables â†’ dbt/Spark â†’ Gold Tables
                    â”‚
                    â””â”€â”€ Metrics: daily_sales, customer_segments, funnel_analysis
```

### Step 4: Serving (ClickHouse)
```
Gold Tables (Iceberg/MinIO) â†’ ClickHouse (IcebergS3 Engine)
                                      â”‚
                                      â””â”€â”€ Zero-Copy Architecture
```

### Step 5: Visualization (Superset)
```
ClickHouse â†’ Superset â†’ Dashboards
                 â”‚
                 â””â”€â”€ KPIs: Revenue, Conversion Rate, Customer Segmentation
```

## ğŸ“Š Báº£ng Dá»¯ Liá»‡u

### Bronze Layer
| Table Name | Description | Partitioning |
|------------|-------------|--------------|
| `events_raw` | Raw event data | `event_date` (day) |

### Silver Layer
| Table Name | Description | Partitioning |
|------------|-------------|--------------|
| `events_cleaned` | Cleaned events | `event_date`, `event_type` |
| `products` | Product dimension | None |
| `users` | User dimension | None |

### Gold Layer
| Table Name | Description | Partitioning |
|------------|-------------|--------------|
| `daily_sales` | Daily sales by category | `sale_date` |
| `funnel_analysis` | Conversion funnel | `analysis_date` |
| `customer_rfm` | RFM segmentation | `segment_date` |

## ğŸ” Cáº¥u HÃ¬nh Káº¿t Ná»‘i

### MinIO
```
Endpoint: http://minio:9000
Access Key: minioadmin
Secret Key: minioadmin123
Bucket: lakehouse
```

### Iceberg REST Catalog
```
URI: http://iceberg-rest:8181
Warehouse: s3://lakehouse/warehouse
```

### ClickHouse
```
Host: clickhouse
Port: 8123 (HTTP), 9000 (Native)
Database: lakehouse
```

### Superset
```
URL: http://localhost:8088
Admin: admin / admin
```

## âš¡ Tá»‘i Æ¯u Hiá»‡u NÄƒng

### Iceberg Optimizations
- **Partitioning**: Theo `event_date` (daily partitions)
- **Z-Ordering**: Theo `user_id`, `product_id` cho truy váº¥n nhanh
- **Compaction**: Merge small files Ä‘á»‹nh ká»³

### ClickHouse Optimizations
- **Primary Key**: `(event_date, user_id, event_type)`
- **Skip Indices**: Bloom filter trÃªn `product_id`
- **Materialized Views**: Pre-aggregated metrics

## ğŸ• Schema Evolution Demo

Äá»ƒ demo tÃ­nh nÄƒng Schema Evolution cá»§a Iceberg:

1. **NgÃ y T**: Dá»¯ liá»‡u ban Ä‘áº§u (khÃ´ng cÃ³ `payment_method`)
2. **NgÃ y T+1**: ThÃªm cá»™t `payment_method` vÃ o schema
3. **Iceberg**: Tá»± Ä‘á»™ng xá»­ lÃ½, khÃ´ng cáº§n rewrite data

```python
# ThÃªm cá»™t má»›i
spark.sql("""
    ALTER TABLE bronze.events_raw 
    ADD COLUMN payment_method STRING
""")
```

## ğŸ”„ Time Travel Demo

```sql
-- Query data as of 2 days ago
SELECT * FROM bronze.events_raw 
VERSION AS OF 123456789;

-- Query data at specific timestamp
SELECT * FROM bronze.events_raw 
TIMESTAMP AS OF '2024-01-15 10:00:00';
```
